<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Scala | くまくまーZ]]></title>
  <link href="http://maiha.github.com/blog/categories/scala/atom.xml" rel="self"/>
  <link href="http://maiha.github.com/"/>
  <updated>2012-04-03T05:28:16+09:00</updated>
  <id>http://maiha.github.com/</id>
  <author>
    <name><![CDATA[maiha]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ScalaでHbase (基本操作)]]></title>
    <link href="http://maiha.github.com/blog/2012/03/12/hbase-scala/"/>
    <updated>2012-03-12T13:20:00+09:00</updated>
    <id>http://maiha.github.com/blog/2012/03/12/hbase-scala</id>
    <content type="html"><![CDATA[<h3>versions</h3>

<ul>
<li>Scala-2.9.1.final</li>
<li>xsbt-0.11.2</li>
<li>Hbase-0.92.0</li>
<li>Hadoop-1.0.1</li>
</ul>


<h3>build.sbt</h3>

<p>```scala
resolvers += "Apache HBase" at "https://repository.apache.org/content/repositories/releases"</p>

<p>resolvers += "Thrift" at "http://people.apache.org/~rawson/repo/"</p>

<p>libraryDependencies ++= Seq(</p>

<pre><code>"org.apache.hadoop" % "hadoop-core" % "1.0.1",
"org.apache.hbase" % "hbase" % "0.92.0"
</code></pre>

<p>)
```</p>

<h3>使用例 (共通部分)</h3>

<p>```scala
import org.apache.hadoop.hbase.{HBaseConfiguration,HTableDescriptor,HColumnDescriptor}
import org.apache.hadoop.hbase.client.{HBaseAdmin,HTable,Put,Get,Delete,Scan}
import org.apache.hadoop.hbase.util.Bytes</p>

<p>val conf  = new HBaseConfiguration
val admin = new HBaseAdmin(conf)
```</p>

<h3>既存テーブルの情報を取得</h3>

<p><code>hbase shell</code>の<code>list</code></p>

<p><code>scala
admin.listTables.foreach(println)
</code></p>

<pre><code>{NAME =&gt; 'adviewlogs', FAMILIES =&gt; [{NAME =&gt; 'ad', ...
{NAME =&gt; 'users', FAMILIES =&gt; [{NAME =&gt; 'name', ...
</code></pre>

<h3>テーブルの新規作成</h3>

<p><code>hbase shell</code>の<code>create 'songs', 'data'</code></p>

<p><code>scala
val schema = new HTableDescriptor("songs")
schema.addFamily(new HColumnDescriptor("data"))
admin.createTable(schema)
</code></p>

<h3>行の追加</h3>

<p><code>hbase shell</code>の<code>put 'songs', 'row1', 'data:title', '走れ'</code></p>

<p>```scala
val songs = new HTable(conf, "songs")
val put   = new Put("row1".getBytes)
put.add("data".getBytes, "title".getBytes, "走れ".getBytes)
songs.put(put)</p>

<p>```</p>

<h3>行の追加(複数のcf)</h3>

<p><code>hbase shell</code>の<code>put 'songs', 'row2', 'data', {'title'=&gt;'怪盗少女', 'singer'=&gt;'ももクロ'}</code></p>

<p>```scala
val songs = new HTable(conf, "songs")
val put   = new Put("row2".getBytes)
put.add("data".getBytes, "title".getBytes, "怪盗少女".getBytes)
put.add("data".getBytes, "singer".getBytes, "ももクロ".getBytes)
songs.put(put)</p>

<p>```</p>

<h3>行の取得 (cf:qualifier指定)</h3>

<p><code>hbase shell</code>の<code>get 'songs', 'row2', 'data:title'</code></p>

<p>```scala
val songs  = new HTable(conf, "songs")
val get    = new Get("row2".getBytes)
val row2   = songs.get(get)
val title  = row2.getValue("data".getBytes, "title".getBytes)
println(Bytes.toString(title))</p>

<p>```</p>

<pre><code>怪盗少女
</code></pre>

<h3>行の取得 (cf内全部)</h3>

<p><code>hbase shell</code>の<code>get 'songs', 'row2', 'data'</code></p>

<p>```scala
import scala.collection.JavaConversions._     // for entrySet:java.util.Set</p>

<p>val songs  = new HTable(conf, "songs")
val get    = new Get("row2".getBytes)
val row2   = songs.get(get)
val cf     = row2.getFamilyMap("data".getBytes)</p>

<p>for (entry &lt;- cf.entrySet) {
  val key   = Bytes.toString(entry.getKey)
  val value = Bytes.toString(entry.getValue)
  printf("%s: %s\n", key, value)
}
```</p>

<pre><code>singer: ももクロ
title: 怪盗少女
</code></pre>

<p>存在しない場合は <code>getFamilyMap</code>が<code>null</code> (要チェック)</p>

<h3>行の削除 (cf指定)</h3>

<p><code>hbase shell</code>の<code>delete 'songs', 'row1', 'data'</code> (shellではqualifierがないと動かない?)</p>

<p>```scala
val songs  = new HTable(conf, "songs")
val del    = new Delete("row1".getBytes)
del.deleteFamily("data".getBytes)
songs.delete(del)</p>

<p>```
存在しない場合はnop</p>

<h3>行の削除 (1行全体)</h3>

<p><code>hbase shell</code>の<code>delete 'songs', 'row2'</code>みたいなこと (これもshellではできない)</p>

<p>```scala
val songs  = new HTable(conf, "songs")
val del    = new Delete("row2".getBytes)
songs.delete(del)</p>

<p>```
存在しない場合はnop</p>

<h3>件数取得</h3>

<p><code>hbase shell</code>の<code>count 'songs'</code></p>

<p>自分でscanするしかない？
<code>org.apache.hadoop.hbase.mapreduce.RowCounter</code> あたりを使う？</p>

<h3>行の存在確認</h3>

<p><code>hbase shell</code>にはない</p>

<p>```scala
val songs  = new HTable(conf, "songs")
val get    = new Get("row3".getBytes)
songs.exists(get)</p>

<p>```</p>

<h3>範囲取得</h3>

<p>検索用データとして以下を <code>hbase shell</code> で追加 (ROW_KEY: 発売日)
<code>ruby
put 'songs', '20090805', 'data:title', 'ももいろパンチ'
put 'songs', '20100505', 'data:title', '怪盗少女'
put 'songs', '20101110', 'data:title', 'ピンキージョーンズ'
put 'songs', '20110706', 'data:title', 'Z伝説'
</code></p>

<p>2010年に発売された曲を調べる</p>

<p><code>scala
val scan = new Scan("2010".getBytes, "2011".getBytes)
val iter = songs.getScanner(scan)
println(iter.size)
</code></p>

<pre><code>2
</code></pre>

<ul>
<li>Scan(start, end)のendは含まれない (ruby の<code>start...end</code>)</li>
<li>HbaseではRAW_KEYによる文字列ソートが保証されている (RAW_KEYの設計が重要)</li>
</ul>


<h3>テーブル削除</h3>

<p><code>hbase shell</code>の<code>disable 'songs'</code>と<code>delete</code>songs'`</p>

<p><code>scala
admin.disableTable("songs".getBytes)
admin.deleteTable("songs".getBytes)
</code></p>

<h3>参考</h3>

<ul>
<li><a href="http://wiki.apache.org/hadoop/Hbase/Scala">http://wiki.apache.org/hadoop/Hbase/Scala</a></li>
<li><a href="http://www.atmarkit.co.jp/fjava/rensai4/bigdata_java03/03.html">http://www.atmarkit.co.jp/fjava/rensai4/bigdata_java03/03.html</a></li>
<li>ScalaからHBaseを使ってみる（0.20.6）<a href="http://www.mwsoft.jp/programming/hadoop/hbase_scala.html">http://www.mwsoft.jp/programming/hadoop/hbase_scala.html</a></li>
<li><a href="http://happy-camper.st/lang/java/hbase/hbase-mapreduce-in-scala.html">http://happy-camper.st/lang/java/hbase/hbase-mapreduce-in-scala.html</a></li>
<li>RowCounter <a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/RowCounter.html">http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/RowCounter.html</a></li>
<li>ももいろクローバーZ <a href="http://ja.wikipedia.org/wiki/%E3%82%82%E3%82%82%E3%81%84%E3%82%8D%E3%82%AF%E3%83%AD%E3%83%BC%E3%83%90%E3%83%BCZ">http://ja.wikipedia.org/wiki/%E3%82%82%E3%82%82%E3%81%84%E3%82%8D%E3%82%AF%E3%83%AD%E3%83%BC%E3%83%90%E3%83%BCZ</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[sbtのインストールメモ]]></title>
    <link href="http://maiha.github.com/blog/2012/03/12/sbt/"/>
    <updated>2012-03-12T12:26:00+09:00</updated>
    <id>http://maiha.github.com/blog/2012/03/12/sbt</id>
    <content type="html"><![CDATA[<h3>Install</h3>

<pre><code>mkdir -p ~/bin
wget -O ~/bin/sbt-launch-0.11.2.jar http://typesafe.artifactoryonline.com/typesafe/ivy-releases/org.scala-tools.sbt/sbt-launch/0.11.2/sbt-launch.jar
echo 'java -Xms512M -Xmx1536M -Xss1M -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=384M -jar `dirname $0`/sbt-launch-0.11.2.jar "$@"' &gt; ~/bin/sbt
chmod u+x ~/bin/sbt
</code></pre>

<h3>Check (zsh)</h3>

<pre><code>rehash
mkdir /tmp/aho
cd /tmp/aho
sbt
&gt; console
scala&gt; 1+2
res0: Int = 3
</code></pre>

<h3>参考</h3>

<ul>
<li><a href="https://github.com/harrah/xsbt/wiki/Getting-Started-Setup">https://github.com/harrah/xsbt/wiki/Getting-Started-Setup</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
